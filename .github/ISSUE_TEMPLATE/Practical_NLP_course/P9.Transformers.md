---
name: Phase09 - Transformers
about: Transformers
title: Phase09 - Transformers
labels: ''
assignees: ''






---

- [ ] Transformer Basics

  - [ ] What are Query, Key and Value matrices and What is their differences?
  - [ ] What is Self-attention mechanism?
  - [ ] What is Positional Encoding?
  - [ ] What is Position-wised MLP?
  - [ ] What is Multi-head Attention?
  - [ ] What is Look-ahead (or triangular) matrices in Decoder section?
  - [ ] What is the superiority of Transformers over RNNs? 
  - [ ] Why Transformers  can preserve long-term contents?
  - [ ] Why Transformer is an Encoder-Decoder model?

- [ ] Transformer Implementation

  - [ ] Implement transformer 

  - [ ] Design a simple translation model 

    

  

  

