## دسته‌بندی متون

یکی از کارهای نسبتا ساده در حوزه پردازش زبان طبیعی، دسته‌بندی متون است. این کار با وجود سادگی، کاربردهای زیادی دارد. به عنوان نمونه کاربردهای این حوزه در مسائل نیز بروز می‌کند:

1. تشخیص هرزنامه در ایمیل (Spam Mail Detection)
2. دسته‌بندی ایمیل در چندین پوشه (Email Foldering)
3. دسته‌بندی اخبار (News Classification)
4. تشخیص زبان یک متن (Language Identification)
5. تحلیل احساسات در یک متن (Sentiment Analysis)
6. ...

در این مسئله ورودی یک سند (document) یا یک متن کوتاه (short text) است. همچنین خروجی مسئله نیز تعدادی کلاس است که کلیه دادگان در این کلاس‌ها دسته‌بندی می‌شوند. 

وابسته به این که کلاس‌های داده چگونه هستند، می‌توان این مسئله را به سه صورت زیر در نظر گرفت:

1. دوکلاسه (Binary) در مقابل چندکلاسه (Multiclass)
2. کلاس‌های تخت (Flat) در مقابل کلاس‌های سلسله مراتبی (Hierarchical)
3. کلاس‌های سخت  (Hard) در مقابل کلاس‌های نرم (Soft) یا چند برچسبی (Multi-label)



به طور کلی اگر مسئله دارای دو کلاس باشد به آن دو کلاسه و اگر دارای بیش از دو کلاس باشد به آن چندکلاسه می‌گویند. 

همچنین یک مسئله دسته‌بندی را دارای کلاس‌های تخت می‌گویند اگر هیچ یک از کلاس‌ها خود دارای یک زیرکلاس نباشد. در غیر این صورت آن مسئله دسته‌بندی دارای کلاس‌های سلسله مراتبی است. به عنوان نمونه اگر در یک مسئله دسته‌بندی دو کلاسه از ما خواسته شود که تشخیص دهیم که یک متن سیاسی است یا خیر، آن گاه این مسئله دارای دو کلاس تخت است. اما اگر از ما خواسته شود تا در صورتی که متن سیاسی بود، آن‌گاه تشخیص دهیم که آن متن مربوط به سیاست داخلی است یا خارجی، مسئله دارای یک کلاس سلسله مراتبی خواهد بود.

علاوه بر دو حالت فوق، ممکن است که هر نمونه از داده به بیش از یک کلاس نسبت داده شود. در این صورت مسئله را چند برچسبی یا دارای کلاس‌های نرم گویند. در غیر این صورت، آن مسئله دارای کلاس‌های سخت است. به عنوان نمونه اگر یک متن هم سیاسی باشد هم اقتصادی آن گاه باید به آن دو برچسب اختصاص داده شود.



در ادامه این بخش قصد داریم تا با دو مسئله دسته‌بندی متون آشنا شویم. اولین مسئله مد نظر ما در این جا، مسئله دسته‌بندی اخبار به چندین مقوله است. به عنوان نمونه مقوله سیاسی، ورزشی، اقتصادی و ... .

 دومین مسئله مد نظر ما در این جا تحلیل احساسات یک متن است. احساس افراد به یک متن ممکن است منفی، مثبت یا خنثی باشد. البته می‌توان برای میزان احساس مثبت یا منفی نیز درجه‌بندی انجام داد. مثلا از بسیار منفی یا مثبت تا کمی منفی یا مثبت.

اکنون برای این که شما بتوانید یک دسته‌بند طراحی کنید، نیاز دارید تا ابتدا یک مدل یادگیر را انتخاب کنید. همانند سایر مسائل، در این جا نیز می‌توان از تکنیک‌های مختلف یادگیری ماشین استفاده کرد. به علاوه می‌توان برای مسائل مرتبط با متن مدل‌های خاص منظوره‌ای وجود دارد که شما می‌توانید از آن‌ها استفاده کنید. به عنوان نمونه مدل‌هایی نظیر مدل مخفی مارکوف یا Hidden Markov Model (HMM)  بیشتر مرتبط با پردازش زبان طبیعی و پردازش گفتار مورد استفاده قرار می‌گیرند. همچنین شبکه‌های عصبی بازگشتی نظیر LSTM و GRU نیز چنین هستند.

اما ما در این جا از شما می‌خواهیم که از ساده‌ترین دسته‌بند شروع کنید و سپس به دسته‌بند پیچیده‌تر برسید. به همین سپس شما از یک مدل Naive Bayes شروع می‌کنید و با یک مدل بازگشتی کار خود را به پایان می‌رسانید.





> تمرین1: ابتدا مجموعه داده همشهری که شامل تمامی اخبار همشهری است را از این  لینک دانلود کنید. سپس یک مدل Naive Bayes آموزش دهید که بتواند اخبار را در مقوله‌های مختلف، دسته‌بندی کند. مدل خود را با معیارهای دقت Precision، Recall و F1-score ارزیابی کنید.
>
> توجه: نیازی به استفاده از کل متن یک خبر برای دسته‌بندی آن نیست. صرفا از عنوان خبر و بخش ابتدایی خبر استفاده کنید.





> تمرین2: برای مجموعه داده همشهری، یک مدل LSTM آموزش دهید.
>
> توجه: ابتدا متن را توکن‌سازی کنید. سپس از یک لایه تعبیه، یک لایه LSTM و یک لایه تماما متصل استفاده کنید. مدل خود را با روش‌های گفته شده در تمرین قبل ارزیابی کنید.
>
> برای آشنایی با لایه تعبیه در pytorch به [این لینک](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#:~:text=A%20simple%20lookup%20table%20that%20stores%20embeddings%20of%20a%20fixed%20dictionary%20and%20size.) و [این لینک](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html) مراجعه کنید.







> تمرین3: تمرین قبل را مجدد در نظر بگیرید. وزن‌های لایه تعبیه را با یک مدل تعبیه Word2vec فارسی، مقداردهی اولیه کنید و مجددا مدل را آموزش دهید.









> تمرین4: ابتدا مجموعه داده تحلیل احساسات را از [این جا](https://github.com/Talkademy/AI-Internship/blob/main/Projects/data/Labeled-Sentences.xlsx) دانلود کنید. سپس سه تمرین قبلی را برای آن تکرار کنید. 



