حوزه پردازش زبان طبیعی یا NLP مبتنی بر متون و جملات شکل می‌گیرد. بنابراین آشنایی با جملات و نحوه صحیح نمایش آن‌ها از اهمیت ویژه‌ای برخوردار است. در ادامه به چیستی جملات می‌پردازیم.

## نحوه‌ی نمایش اجزای جمله

 ابتدا لازم است تا متغیر قیاسی (Categorical)، ترتیبی (Ordinal) و عددی (Numerical) را تعریف کنیم. 

·     **متغیر قیاسی** متغیری است که می‌تواند مقادیر عددی محدود و معمولا ثابت، مقادیر اسمی (Nominal) و یا مقادیر کیفی مرسوم در هر نوع از مشاهده یا آزمایش را اتخاذ کند. به زبان ساده به متغیری که به دو یا چند دسته از مقادیر قابل تفکیک باشد متغیر قیاسی گفته می‌شود. به عنوان مثال متغیر باینری که دو مقدار صفر و یک را اتخاذ می‌کند نیز یک متغیر قیاسی است. این نوع متغیر را متغیر اسمی نیز می‌نامند. 

·     **متغیر ترتیبی** نوعی متغیر قیاسی است که دارای یک ترتیب خاص بوده و فاصله‌ی بین مقادیر آن مشخص نیست. به عنوان نمونه دسته‌بندی مدرک تحصیلی افراد به سه گروه *کارشناسی*، *ارشد* و *دکتری* را می‌توان از این نوع متغیر در نظر گرفت که علاوه بر داشتن یک ترتیب مشخص به صورت اسمی نیز می‌باشد.

**·**     **متغیر عددی** متغیری است که در یک بازه‌ی مشخص بتواند هر عددی را به خود بگیرد. در این نوع متغیر، فاصله‌ی بین اعداد یک ترتیب را برای متغیر ایجاد می‌کند و از این جهت این متغیر نوعی متغیر ترتیبی نیز محسوب می‌شود. به عنوان مثال حقوق کارمندان نوعی داده‌ی عددی محسوب می‌شود.

وقتی با مدل‌های یادگیری نظیر شبکه‌های عصبی یا ماشین بردار پشتیبان یا رگراسیون مواجه می‌شویم همواره کار با داده‌ی عددی بسیار ساده‌تر از کار با داده‌ی قیاسی یا عددی می‌باشد. دلیل این مسئله این است که این مدل‌های یادگیر با بردارها، ماتریس‌ها و یا تنسورهای با ابعاد بالا کار می‌کنند. به همین سبب در مواجهه با داده‌های قیاسی یا ترتیبی، نخست باید به گونه‌ای آن را به یک بردار، ماتریس و یا تنسور تبدیل نمود اما چگونه؟ این مسئله همواره چالش‌برانگیز بوده است چون یک شیوه‌ی مشخص برای این‌کار وجود ندارد و در بسیاری از مواقع به ابتکار افراد وابسته است. اما تعدادی روش شناخته شده برای انجام این کار وجود دارد که در ادامه برای جملات بررسی می‌شود. 

جمله در زبان یک داده‌ی دنباله‌ای و قیاسی است. جمله را می‌توان دنباله‌ای از کاراکترها و یا دنباله‌ای از کلمات درنظر گرفت. که به تبع کلمات یا کاراکترها داده‌ی قیاسی محسوب می‌شوند. البته در صورت لزوم می‌توان با در نظر گرفتن n کلمه یا کاراکترِ کنار یکدیگر، یک واحد جدید زبانی تحت عنوان n-gram برای ساخت دنباله ایجاد کرد. اما سوال چالش‌برانگیز این است که در صورت تجزیه‌ی جمله به هر نوع واحد دلخواه، چگونه می‌توان آن را نمایش داد؟ روش‌هایی نظیر کدگذاری عدد صحیح یا کدگذاری One-hot از جمله روش‌هایی است که برای کلیه داده‌های قیاسی می‌تواند مورد استفاده قرار گیرد. اما روش‌هایی نظیر مدل بسته کلمات (Bag Of Words)، ساخت ماتریس فراوانی اصطلاح- معکوس فراوانی متن (Term Frequency-Inverse Document Frequency)  و استفاده از تعبیه‌ی ویژگی (Feature embedding) از جمله روش‌هایی است که در حوزه‌ی پردازش زبان طبیعی بیشتر مورد استفاده قرار می‌گیرد. 

همچنین در دو صورت می‌توان برای یک جمله یک نمایش ارائه کرد. نخست این که برای هر واحد زبانی صرف نظر از متن زمینه (context) یک نمایش ارائه کنیم. یا اینکه که برای هر واحد زبانی با توجه به متن زمینه یک نمایش ارائه دهیم. به عنوان نمونه کلمه‌ی "شیر" تا زمانی که در داخل یک متن قرار نگیرد نمی‌توان تشخیص داد که منظور گوینده چیست. به همین منظور روش‌هایی برای نمایش واحدهای زبانی با توجه به متن ارائه شد که به آن‌ها تعبیه زمینه‌ای (contextualized embedding) می‌گویند. متدهایی نظیر Elmo، BERT، RoBERTa، XLNet و XLMRoBERTa از این دسته هستند. 

علاوه بر دسته‌بندی‌ای که ارائه کردیم، نکته مهمی که در این جا وجود دارد این است که آیا می‌توان یک واحد زبانی را با یک بردار به طول دلخواه نمایش داد یا خیر؟ همچنین سوال دیگر که به وجود می‌آید این است که آیا مقادیر عددیِ بردار می‌توانند هر عدد پیوسته‌ای باشند یا این که فقط اعداد صحیح مجاز به استفاده است؟ این سوالات باعث به وجود آمدن نمایش جملات با دسته‌بندی خلوت (sparse) و چگال (dense) شده است. به طور کلی هر چه که طول برداری که با آن یک واحد زبانی  را نشان می‌دهیم بیشتر باشد، ما این قابلیت را خواهیم داشت که بردار خلوت ساخته و عناصر موجود در آن به اعداد صحیح نزدیک‌تر باشند. اما هر چه طول بردار کم می‌شود، بردار چگال‌تر شده و از خلوتی بردار کاسته می‌شود. با توجه به این توضیحات، نمایش One-hot خلوت‌ترین نوع نمایش است. همچنین نمایش‌هایی که از بردارهای تعبیه حاصل می‌شوند معمولا بسیار چگال هستند.



### بررسی یک نوع نمایش خلوت (sparse) از جملات - نمایش One-hot

روش One-hot با وجود تمام مشکلاتی که دارد هنوز پرکاربردترین روش نمایش کلاس‌های یک داده می‌باشد. همچنین در صورتی که جمله را به کاراکتر تجزیه کنیم این روش برای نمایش جمله کارآمد می‌باشد. گفته شد که برای نمایش یک جمله در زبان اولین گام این است که آن را به واحدهای کوچکتر مانند کاراکترها، کلمات یا n-gramها تجزیه کنیم. پس از تجزیه، باید هر واحد به صورت یک بردار نمایش داده شود. در اینجا برای سادگی فرض می‌کنیم جملات به کلمات تجزیه شده باشد (برای کاراکترها و سایر واحدهای کوچتر نیز روش کار تفاوتی ندارد). بنابراین باید هر کلمه به صورت یک بردار نمایش داده شود. برای تبدیل کلمات به بردار توسط روش کدگذاری One-hot نخست باید مجموعه واژگان موجود در دیتاست به دست آید. به عنوان مثال فرض کنید دیتاست دارای دو جمله به این صورت باشد: "من یک دانشجو هستم" و "من امروز می‌آیم". در این صورت مجموعه واژگان به صورت  زیر می‌باشد.

مجموعه واژگان دیتاست فرضی

| امروز: 1 | دانشجو: 2 | من: 3 | می‌آیم: 4 | هستم: 5 | یک: 6 |
| :------: | :-------: | :---: | :------: | :-----: | :---: |

 

در مرحله‌ی بعد دقیقا مشابه آنچه که در جدول فوق باید به هر یک از کلمات یک اندیس نسبت داده شود. ترتیب اندیس‌گذاری می‌تواند به هر شکل ممکنی باشد اما باید توجه داشت که در ادامه‌ی کار نباید این ترتیب گم شود. در اینجا متناسب با ترتیب حروف الفبا اندیس‌گذاری انجام شده است. از این گام به بعد دیگر نیاز به کلمات نیست و می‌توان با استفاده از اندیس‌ها کار را ادامه داد. حال به ازای هر یک از اندیس‌ها یک بردار One-hot ساخت می‌شود. برای ساخت این بردار فرض کنید اندیس یک کلمه برابر$i$ و $n$ تعداد کل واژگان باشد، در اینصورت بردار $x_i = (x_{i,1}, ..., x_{i,n})$ که $x_{i,i}=1$ و $x_{i,j}=0$ و $i\neq j$، بردار مورد نظر می‎‌باشد. به عبارت بهتر بردار One-hot برداری است که فقط یک عنصر آن برابر 1 است و بقیه‌ی عناصر آن صفر هستند. عنصر برابر با 1 نیز عنصری است که اندیس آن برابر با اندیس کلمه‌ای است که قصد نمایش آن را داریم. برای فهم بهتر مطلب می‌توانید دو جدول زیر که بردارهای One-hot تمام کلمات دو جمله‌ی مذکور را نشان می‌دهد را مشاهده کنید.

|  بردار One-hot  | اندیس |  کلمه  |
| :-------------: | :---: | :----: |
| $(0,0,1,0,0,0)$ |   3   |   من   |
| $(0,0,0,0,0,1)$ |   6   |   یک   |
| $(0,1,0,0,0,0)$ |   2   | دانشجو |
| $(0,0,0,0,1,0)$ |   5   |  هستم  |



|  بردار One-hot  | اندیس | کلمه  |
| :-------------: | :---: | :---: |
| $(0,0,1,0,0,0)$ |   3   |  من   |
| $(1,0,0,0,0,0)$ |   1   | امروز |
| $(0,0,0,1,0,0)$ |   4   | می‌آیم |





> تمرین1: ابتدا روش‌های نمایش Bag of Words و TFIDF را مطالعه کنید. سپس پنجاه جمله در زبان فارسی بنویسید و با استفاده از این دو روش تمامی جملات را نمایش دهید. این کار در زبان پایتون و بدون استفاده از کتابخانه‌های آماده انجام دهید. در انتها توضیح دهید چرا این روش‌ها خلوت محسوب می‌شوند.
>
> توجه: برای آشنایی با این دو مفهوم می‌توانید به [این لینک](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) مراجعه کنید.



### نمایش چگال جملات

یک از شیوه‌ها برای رسیدن به یک نمایش چگال از جملات این است که نمایش خلوت را با روش‌هایی نظیر الگوریتم PCA و SVD کاهش بعد داده و یک نمایش چگال برای هر واحد زبانی به دست آوریم. اما این روش برای مجموعه دادگان حجیم هزینه محاسباتی بالایی دارد. به همین خاطر در این حوزه روش‌هایی نظیر Word2vec، Glove و Fasttext ارائه شد. از بین این روش‌ها ما در این جا به Word2vec می‌پردازیم. این روش از شبکه‌های عصبی بهره می‌گیرد و یک نمایش چگال از واحدهای زبانی به دست می‌آورد. مقاله مربوط به Word2vec را می‌توانید از [این جا](https://arxiv.org/pdf/1301.3781.pdf) مطالعه کنید. 





> تمرین2: برای پنجاه جمله‌ای را که در تمرین قبل نوشته بودید با استفاده از Word2vec یک نمایش چگال ارائه کنید. این کار را در زبان پایتون و با استفاده از کتابخانه gensim انجام دهید.

