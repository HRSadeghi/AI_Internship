<div dir="rtl" align='right'>

در این بخش به مرور مباحث یادگیری ماشین می‌پردازیم. پیش‌فرض ما در این جا این است که شما با این مباحث آشنایی دارید و این مباحث صرفا جنبه مرور و یادآوری دارد.

به طور کلی اگر بخواهیم یک دسته‌بندی از هوش مصنوعی ارائه دهیم می‌توانیم به شکل زیر اشاره کنیم:

![](AI_field.png)

به طور کلی یادگیری ماشین یک زیرمجموعه از هوش مصنوعی است که با سایر حوزه‌های هوش مصنوعی ارتباط تنگاتنگی دارد. اگر بخواهیم یک هدف کلی برای یادگیری ماشین مشخص کنیم می‌توانیم بگوییم که کار یادگیری ماشین تخمین تابع است. در واقع در حوزه یادگیری ماشین تلاش داریم تا روابط بین پدیده‌ها را با یک تابع مدل کنیم. این تابع می‌تواند با دریافت یک یا چند ورودی، یک یا چند خروجی را برای ما تولید کند.

اگر بخواهیم یک نگاه کلی به یادگیری ماشین بیندازیم و آن را با برنامه‌نویسی عادی مقایسه کنیم، می‌توانیم بگوییم که در برنامه‌نویسی، برنامه و داده ورودی به ماشین داده می‌شود و ماشین با اجرای برنامه بر روی داده ورودی، داده خروجی را تولید می‌کند. اما در یادگیری ماشین، نتوانیم برای تولید داده خروجی از ورودی برنامه‌ای بنویسیم. لذا هم داده ورودی و هم داده خروجی به ماشین داده می‌شود و از این جا به بعد، وظیفه‌ی به دست آوردن برنامه مناسب برای تولید خروجی از ورودی به عهده ماشین خواهد بود. به شکل زیر توجه کنید.

![](com.png)



اما برای این که ماشین بتواند رابطه بین ورودی و خروجی را تشخیص دهد باید روش‌ها و الگوریتم‌هایی را به ماشین بدهیم که بتواند رابطه بین ورودی و خروجی را تشخیص دهد. برخی از مهم‌ترین این الگوریتم‌ها در زیر لیست شده‌اند:

- Linear Regression

- Logistic Regression

- K-Nearset Neighbors (KNN)

- Support Vector Machine (SVM)

- Naive Bayes

- Decision Tree

- Random Forest

- Single Perceptron

- Neural Networks

- K-means

- Principal Component Analysis (PCA)


از بین این الگوریتم‌ها، 9 مورد ابتدایی را باناظر (supervised) گویند و مابقی را بدون‌ناظر یا (Unsupervised) گویند. در الگوریتم‌های باناظر بدین صورت عمل می‌شود که زوج داده ورودی و خروجی (یعنی ${(x,y) \in X \times Y}$) همزمان در دسترس ما است و مدل برای آموزش از آن استفاده می‌کند. اما در الگوریتم‌های بدون‌ناظر فقط داده ورودی در دسترس است و مدل هیچ‌گونه بازخوردی بابت خروجی‌ای که در هنگام آموزش تولید می‌کند دریافت نمی‌کند. 

اکنون به بررسی اجمالی چند مورد از این الگوریتم‌ها خواهیم پرداخت. 

## الگوریتم رگرسیون خطی

در الگوریتم رگرسیون خطی یک مدل خطی نظیر $\hat{y} = w.x + b$ با ضرایب $w=(w_1, w_2 ,..., w_k) \in \mathbb{R}^k$ و بایاس $b \in \mathbb{R}$ به دادگان برازش می‌شود. برای یافتن ضرایب و بایاس بهینه کافی است تا ضرایب تا تابع خطا زیر را بهینه  کنیم:

$$\ell = \frac{1}{n-1} (y-\hat{y})^2 $$

که در رابطه فوق $n$ تعداد نمونه‌ها،  $y$ خروجی واقعی متناسب با ورودی $x$  و $\hat{y}$ خروجی پیش‌بینی شده مدل می‌باشد. برای پیاده‌سازی این بخش از کتابخانه sklearn پایتون استفاده خواهیم کرد. برای اطلاعات بیشتر به [این لینک](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) مراجعه کنید. 





> تمرین 1: تابع $y = sin(x) \;  0 \leq x \leq \frac{\pi}{2}$ را در نظر بگیرید. با استفاده از کتابخانه sklearn یک مدل رگرسیون خطی بر این تابع برازش کنید و خطای مدل خود را گزارش کنید.



## الگوریتم k نزدیک‌ترین همسایه (KNN)

برخلاف مدل رگرسیون خطی که یک مدل برای برازش توابع است، این الگوریتم یک دسته‌بندی است. این الگوریتم بدین صورت عمل می‌کند که فاصله یک داده ورودی را از تمامی دادگان ورودی موجود در مجموعه داده محاسبه می‌کند و سپس از بین k نمونه‌ای که از همه به داده ورودی جدید نزدیک‌تر هستند، کلاس‌های متناظر آن‌ها را در نظر می‌گیرد و بین آن کلاس‌ها رای‌گیری انجام می‌دهد و کلاسی که بیشترین تکرار را در بین این k همسایه داشته باشد به عنوان خروجی در نظر گرفته می‌شود. این الگوریتم به عنوان یک الگوریتم تنبل شناخته می‌شود، زیرا فاز آموزش ندارد و هر مرتبه باید تمام دادگان را اسکن کند.



> تمرین2: دادگان دو کلاسه زیر را در نظر بگیرید:
>
> $x_1  = (1,1) $, $y_1 = 1$
>
> $x_2  = (0,1) $, $y_2 = 1$
>
> $x_3  = (2,4) $, $y_3 = -1$
>
> $x_4  = (-2,1) $, $y_4 = -1$
>
> $x_5  = (1,3) $, $y_5 = 1$
>
> $x_6  = (9,1) $, $y_6 = -1$
>
> اکنون با استفاده از الگوریتم KNN برای k=3 هم به صورت دستی و هم با استفاده از کتابخانه sklearn  کلاس متناظر به داده $x=(0, 0)$ را بیابید. برای آشنایی با نحوه آموزش مدل KNN با استفاده از کتابخانه sklearn  به [این لینک](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) مراجعه کنید.



## الگوریتم بیز ساده (Naive Bayes)

الگوریتم بیز ساده همانند الگوریتم KNN یک دسته‌بند است. این الگوریتم مبتنی بر قانون بیز در احتمال طراحی شده است. اگر داده ورودی $x=(x_1, x_2, ..., x_n)$ در دسترس ما باشد و مسئله ما نیز شامل کلاس‌های ${C_1, ..., C_k}$ باشد، آنگاه برای این که مشخص شود داده ورودی $x$ به کدام کلاس تعلق دارد کافی است تا شرطی $P(C_i|x)$ که $i \in {1, ..., k}$ محاسبه شود. اکنون کافی است تا کلاس متناظر با بیشترین احتمال شرطی را انتخاب کنیم و به عنوان کلاس خروجی در نظر بگیریم. یعنی $C^* = \underset{i=1,..,k}{argmax P(C_i|x)}$.

اما بخش اصلی در اینجا محاسبه $P(C_i|x)$ می‌باشد. واضح است که نمی‌توان این احتمال را به صورت مستقیم از دادگان تخمین زد. به همین سبب از قاعده بیز در احتمال به صورت زیر کمک می‌گیریم: