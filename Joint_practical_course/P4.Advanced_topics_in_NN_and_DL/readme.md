# شبکه‌های عصبی عمیق

در این چند سالی که از عمر هوش مصنوعی می‌گذرد، تحقیقات در این رشته سبب شده است که بسیاری از مسائل که تا سالیان درازی برای انسان قابل حل نبود، به سادگی توسط ماشین قابل حل شود. یکی از تاثیرگذارترین زیرشاخه‌ها از هوش مصنوعی که این موضوع را سبب می‌شود، زیرشاخه‌ی یادگیری ماشین می‌باشد که با توسعه‌ی شبکه‌های عصبی توانست ارتباط بین پدیده‌های طبیعی را که گاها دارای پیچیدگی زیادی بودند، کشف کند. اما عدم کشف ویژگی مناسب و هزینه محاسباتی بسیار زیاد در داده‌های با ابعاد بالا سبب شد تا نتوان از روش‌های یادگیری ماشین و به ویژه محبوب‌ترین این تکنیک‌ها نظیر شبکه‌های عصبی و ماشین بردار پشتیبان استفاده کرد. یک راه حل ساده برای رهایی از این مشکل طراحی روش‌هایی بود که بتوانند همزمان با یادگیریِ روابط بین داده‌ها، عملیات استخراج ویژگی را نیز انجام دهند و این سرآغازی بر شبکه‌های عصبی عمیق بود. در ادامه چندین شبکه‌ی عصبی عمیق را مورد بررسی قرار می‌دهیم.

## شبکه‌های عصبی خودکدگذار (Autoencoder)

شبکه‌ی عصبی خودکدگذار شبکه‌ای است که ورودی‌اش را در خروجی‌اش بازسازی می‌کند . در این نوع از شبکه عصبی ابتدا باید ورودی را به داده‌ی کد شده تبدیل نمود و سپس داده‌ی کد شده را مجددا به شکل اولیه ورودی تبدیل کرد. در شکل زیر لایه‌ی $h$ نشان‌دهنده‌ی یک لایه‌ی مخفی است که حاصل آن داده‌ی کد شده می‌باشد. این شبکه عصبی ممکن است به صورت دو بخشی در نظر گرفته شود: یک تابع کدگذار  $h=f(x)$ و یک تابع کدشکن $r=g(h)$. معماری این شبکه را درشکل زیر مشاهده می‌کنید.

 <img src="./autoencoder.png" alt="Picture" width="200" height="150" style="display: block; margin: 0 auto" />

ایده‌ شبکه‌های عصبی خودکدگذار مربوط به سالیان اخیر نیست بلکه پیشینه‌ای طولانی در عمر شبکه‌های عصبی دارد. به صورت سنتی شبکه‌های عصبی خودکدگذار برای کاهش بعد و یادگیری ویژگی، بسیار استفاده می‌شوند اما ارتباط بین متغیر مخفی و شبکه‌های عصبی خود رمزگذار باعث به وجود آمدن شبکه‌های عصبی خودکدگذارِ تغییراتی با کارایی بسیار بالا شده است که این موضوع سبب شده است شبکه‌های عصبی خودرمزگذار در صدر روش‌های مولد قرار گیرد.

یکی از راه‌کارهایی که سبب می‌شود شبکه‌های عصبی خودکدگذار ویژگی‌های مناسبی را پیدا کند این است که لایه‌ی *$h$ * را محدود کنیم که تعداد واحدهای (نورون‌های) آن از تعداد واحدهای ورودی کمتر باشد. این نوع از شبکه‌های عصبی خودکدگذار را که اندازه لایه مخفی از لایه ورودی کمتر است شبکه‌های عصبی خودکدگذار ناکامل می‌گویند. 

فرایند آموزش این شبکه‌ها با کمینه کردن تابع خطای زیر انجام می‌شود. 

$$\ell(x, g(f(x)))$$

که در آن $\ell$ تابع خطایی است که $g(f(x))$ را در صورت عدم شباهت به خروجی هدف جریمه می‌کند.



> تمرین1:  با استفاده از سه لایه شبکه عصبی تماما متصل، یک شبکه عصبی خودکدگذار طراحی کنید که تصاویر دست‌نویس مجموعه داده MNIST را در خروجی بازسازی کند. (از کتابخانه pytorch برای این کار استفاده کنید). توجه شود که برای انجام این پروژه یک روز کفایت می‌کند.





## شبکه‌های عصبی پیچشی یا کانولوشنی (CNN)

شبکه‌ی عصبی کانولوشنی (CNN)  نوعی شبکه‌ی عصبی است که بر روی داده‌هایی که دارای توپولوژی مشبکه است عملکرد بسیار خوبی را از خود نشان می‌دهد. برای مثال داده‌های سری زمانی که می‌توان آن را به صورت مشبکه‌ی یک بعدی در طول بازه‌های زمانی مشخص در نظر گرفت یا داده‌های تصویر که می‌توان آن را به صورت مشبکه‌ی دو بعدی در نظر گرفت. شبکه‌های عصبی CNN عملکرد فوق‌العاده‌ای را از خود در کارهای عملی به جا گذاشته است. 

### عملگر کانولوشن

عبارت "کانولوشن" در نام این نوع از شبکه‌ی عصبی این موضوع را مشخص می‌کند که عملیات ریاضی کانولوشن در این شبکه‌ی عصبی اعمال شده است. عملیات کانولوشن به صورت کلی بر روی تنسور با هر بعدی قابل انجام است. اما برای سادگی فرض می‌کنیم داده‌ی ورودی تنها به متغیر $t$ وابسته باشد (عملیات کانولوشن یک بعدی). در این صورت عملیات کانولوشن مطابق رابطه ‏زیر تعریف می‌شود. نماد $*$ نشان‌دهنده‌ی عملگر کانولوشن است.

$$s(t) = (x*y)(t)$$

$$s(t)=\sum_{a=-\infty}^{\infty} x(x).w(t-a)$$

در واژه‌شناسی شبکه عصبی کانولوشنی در رابطه فوق، اولین آرگون یعنی $x$ را داده‌ی ورودی، دومین آرگومان یعنی $w$ را هسته (کرنل یا فیلتر) و $s(t)$ را نگاشت ویژگی (فیچر مپ) می‌نامند. در رابطه فوق کرانی برای $t$ در نظر گرفته نشده است اما در صورت که $t$ محدود باشد کران متانظر با آن به رابطه اعمال می‌شود.

#### سه ایده‌ی اصلی در CNNها

شبکه‌های عصبی کانولوشنی از سه ایده‌ی بسیار مهم و اساسی استفاده می‌کنند که این سه ایده عبارتند از: 1) اتصال اسپارس2) اشتراک پارامترها 3) ثابت بودن نسبت به انتقال

لایه‌های شبکه‌های عصبی MLP از ضرب ماتریس به همراه یک ماتریس وزنی استفاده می‌کنند که هر یک از عناصر ماتریس به صورت جداگانه نشان‌دهنده‌ی ارتباط یک واحد (نورون) ورودی و یک واحد (نورون) خروجی است. این موضوع سبب می‌شود که تعداد پارامترها به شکل قابل ملاحضه‌ای زیاد شود. اما شبکه‌های عصبی CNN از اتصال اسپارس یا پراکنده بهره می‌برد. به عنوان نمونه فرض کنید یک تصویر هزاران یا چند میلیون پیکسل داشته باشد اما فقط قسمتی از تصویر مانند لبه‌هایی که با استفاده از کرنل‌ها به دست آمده است و دارای ده‌ها یا صدها پیکسل است با معنی باشد. این بدین معنی است که نیاز به ذخیره‌سازی تعداد بسیار زیادی از پارامتر نیست و برای بخش‌های با معنی، باید تعداد کمی پارامتر آموزش داده و ذخیره شود. این موضوع سبب کاهش استفاده حافظ توسط مدل به دست آمده می‌شود و نتایج آماری خوبی را به دست می‌دهد. به صورت سنتی اگر $m$ واحد ورودی و خروجی $n$ واحد خروجی برای یک لایه در دسترس باشد آنگاه ماتریس وزن از مرتبه‌ی $O(m \times n)$ است. حال اگر پارامترهای ورودی به هر واحد خروجی را به $k$ محدود کنیم در آن صورت $O(k \times n)$ پارامتر نیاز داریم. باید توجه داشت که غالبا $m$ و $n$ دارای مرتبه یکسان هستند و لذا برای $k$ بسیار کوچکتر از این می‌باشد. در واقع این موضوع سبب می‌شود وزن‌های شبکه اسپارس شود. به شکل زیر توجه کنید.

![](sparse_connection.png)



اکنون با آشنا شدن با مقدمات شبکه‌های عصبی CNN در یک بعد، می‌توانیم این شبکه‌ها را برای دو بعد یا بیشتر تعمیم دهیم. در حالت دوبعدی این شبکه‌ها بر روی تصاویر قابل اعمال هستند. برای آشنایی با این شبکه‌ها در حالت دو بعدی، لایه pooling و انواع معماری‌های شبکه‌های عصبی CNN به [این سری ویدئو](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) از andrew ng مراجعه کنید.





> تمرین2: از مدل کانولوشنی Resnet50 استفاده کرده و یک مدل دسته‌بند برای مجموعه دادگان Cifar10 آموزش دهید. توجه کنید که شما باید دادگان را به سه بخش آموزش (train)، ارزیابی (validation)  آزمون (test) تقسیم کنید. همچنین مدل خود را با معیارهای دقت، Precision، Recall، F1 و ماتریس آشفتگی (Confusion Matrix) ارزیابی کنید.



## شبکه‌ی عصبی بازگشتی (RNN)

شبکه‌ی عصبی بازگشتی یا RNN  یک خانواده از شبکه‌های عصبی می‌باشد که برای پردازش داده‌ی دنباله‌ای نظیر $x = (x_t)_{t=1}^{T}$  طراحی شده است. برخلاف شبکه‌های عصبی MLP، شبکه‌های عصبی RNN صرفا رو به جلو نبوده و دارای دور می‌باشد و با بهره‌گیری از این ویژگی می‌توانند براساس یک تاریخچه‌‌ از خروجی‌های پیشین، خروجی متناسب با ورودی حال حاضر را تولید کنند. مسائلی را که به صورت یک سری زمانی یا به شکل یک دنباله بیان می‌شوند معمولا می‌توان با استفاده از RNNها مورد بررسی قرار داد. به عنوان نمونه برای پیش‌بینی وضعیت آب‌وهوا باید متناسب با وضعیت جوی چند روز گذشته تصمیم‌گیری شود. یا برای پیش‌بینی قیمت ارز باید براساس تغییرات قیمتی آن در بازه‌های گذشته این پیش‌بینی انجام شود.

 اما سوال اساسی این است که چگونه تاریخچه‌ای از داده‌ها را ساخته، نگه داشته و برای پیش‌بینی‌های بعدی مورد استفاده قرار دهیم؟ پاسخ سوال در دور ایجاد شده در شبکه‌ی عصبی RNN نهفته است. با اعمال یک عنصر از دنباله به عنوان ورودی به شبکه‌ی عصبی و دریافت خروجی متناظر آن، می‌توان این خروجی را مجددا به عنوان بازخورد شبکه به عنصر جدید دنباله پیوند داده و به عنوان ورودی جدید به شبکه اعمال کرد. در شکل زیر یک شبکه عصبی RNN را مشاهده می‌کنید. در این شبکه ابتدا عنصر اول دنباله به شبکه داده می‌شود و سپس یک خروجی تولید می‌کند. اکنون با اعمال یک وزن به خروجی، مجدد این خروجی به همراه عنصر بعدی دنباله به شبکه داده می‌شود. این فرایند آنقدر ادامه می‌یابد تا به انتهای دنباله برسیم.

![](./RNN.png)



یکی از مشکلات شبکه‌های عصبی RNN این است که هر چه که طول دنباله افزایش می‌یابد، احتمال فراموش شدن اطلاعات موجود در حافظه که مربوط به عناصر اولیه دنباله است افزایش می‌یابد. همچنین به سبب این که با افزایش طول دنباله عملا شبکه عمیق‌تر می‌شود، لذا آموزش مدل نیز سخت‌تر می‌شود. به همین سبب شبکه‌های عصبی بازگشتی‌ای ارائه شدند که این مشکلات را حل می‌کنند. از جمله این شبکه‌ها می‌توان به LSTM، GRU، Bidirectional LSTM و Bidirectional LSTM اشاره کرد. برای آشنایی با این شبکه‌ها به [این مقاله](https://medium.com/analytics-vidhya/rnn-vs-gru-vs-lstm-863b0b7b1573) و [این ویدئو](https://www.youtube.com/watch?v=jGst43P-TJA) مراجعه کنید. 



> تمرین3: ساختار شبکه‌ی عصبی LSTM را بررسی و تفسیر کنید. هر جز از شبکه عصبی دقیقا چه کاری انجام می‌دهد؟ نحوه آموزش شبکه چگونه است؟ 





> تمرین4: شبکه‌های عصبی RNN را می‌توان به سه صورت  one-to-many، many-to-one و many-to-many مورد استفاده قرار داد. درباره‌ی هر یک تحقیق کنید و برای هر کدام مثالی بیاورید. 



## مباحث تکمیلی شبکه‌های عصبی

### روش‌های تنظیم‌سازی (regularization)

یکی از مشکلاتی که در انواع مدل‌های یادگیر ما را درگیر می‌کند، بحث بیش‌برازش یا (overfitting) است. بیش‌برازش سبب می‌شود که عملکرد مدل بر روی دادگان آزمون بسیار ضعیف‌تر و بدتر از داده‌ی آموزش باشد. برای جلوگیری از این مشکل معمولا از روش‌ تنظیم‌سازی یا regulariztion  استفاده می‌کنیم. روش‌های تنظیم‌سازی متعددی وجود دارند اما در این‌جا صرفا به سه مورد L1، L2، dropout و افزونگی داده یا data augmentation نیاز داریم. برای سه مورد نخست می‌توانید به [این لینک](https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036#:~:text=Regularization%20is%20a%20set%20of,data%20from%20the%20problem%20domain.) و برای مورد آخر می‌توانید به [این لینک](https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/) مراجعه کنید.

با مطالعه موارد فوق بررسی کنید که چه رابطه‌ای بین data augmentation  و regularization وجود دارد.



### کم رنگ شدن گرادیان و انفجار گرادیان

هر چه که شبکه عمیق‌تر می‌شود، آموزش مدل سخت‌تر می‌شود. برای چنین شبکه‌هایی، در حین آموزش، مقدار گرادیانی که برای لایه‌های اولیه شبکه به دست می‌آید ممکن است که به سمت صفر برود. در نتیجه پس از گذشت مدتی از زمان آموزش دیگر وزن این لایه‌ها تغییری نمی‌کند. به این پدیده کم رنگ شدن گرادیان یا vanishing gradient می‌گویند. همین اتفاق ممکن است به صورت برعکس بیفتد. گرادیان به سرعت بزرگ شود و وزن‌ها در حد انفجار برسند. به این پدیده انفجار گرادیان یا exploding gradient می‌گویند. برای مطالعه بیشتر به [این لینک](https://www.youtube.com/watch?v=qhXZsFVxGKo) مراجعه کنید.





> تمرین5:  در تمرین 2 یک مدل Resnet50 را طراحی کردید. با اضافه کردن لایه‌ی dropout به این مدل، مدل خود را بازطراحی کنید و نتایج آن را گزارش کنید. این مدل چگونه مشکل کم‌رنگ شدن گرادیان را حل کرده است. توضیح دهید.
>
> توجه: برای پاسخ به آخرین سوال بررسی کنید که اتصال باقی‌مانده‌ای چیست و چگونه کار می‌کند (residual connection).

### تسک
۱. تسک طبقه بندی ای را که در قسمت معرفی شبکه انجام دادید را در نظر بگیرید. تعداد کل عکسهای آموزش را در دیتاستی که استفاده کردید در نظر بگیرید. این بار  به اندازه ۱/۵ دیتا را به طور رندوم جدا کنید و این دیتای جداشده را به عنوان دیتای آموزشی استفاده کنید. با آموزش این مدل، نشان دهید مدل روی این دیتای جدا شده overfit می شود و باید جلوی آن را بگیریم. سعی کنید حالا با رگولاریزیشن مدل را بهتر کنید. همچنین سعی کنید با استفاده از  dropout و  batch normalization و pooling و augmentation هم در آموزش جدید استفاده کنید و بهبود را مشاهده کنید. 

از این [لینک](https://www.section.io/engineering-education/dropout-regularization-to-handle-overfitting-in-deep-learning-models/) میتوانید برای کمک بیشتر استفاده بگیرید.

۲. در این مرحله میخواهیم از transfer learning استفاده کنیم. 

دیتاست [fashion-Mnist](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html) را دانلود کنید یا از طریق خود pytorch به آنه دسترسی پیدا کنید. حالا به روش های زیر مدل را آموزش دهید:

۱. با یک backbone جدید، مشابه آنچه در بخش intro to NN استفاده کردید، با head ای که به تعداد fashion-mnist کلاس دارد را از اول آموزش بدهید. 

۲. در این قسمت مدلی را که در بخش intro to nn بر روی داده ۶کلاسه آموزش داده بودید لود کنید و head کلاسیفیکیشن را برداشته و head جدیدی که به تعداد fashion-mnist کلاس دارد قرار دهید و در دو حالت ۱. آموزش کل شبکه ۲. آموزش head شبکه را finetune کنید.
نتایج را مقایسه کنید.
